{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvoqWuLY9LiWbFfRfyQ2Fj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timvdstap/ML-AI-learning/blob/main/SOC_obis_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction.\n",
        "\n",
        "This script can be used as a walkthrough of how the master .csv files have been standardized to Darwin Core to facilitate publication of the data to the Ocean Biodiversity Information System."
      ],
      "metadata": {
        "id": "bU3kEz789hT0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "VQFJBZmPidJZ",
        "outputId": "2f935e5b-82dc-4b31-f2d9-ec9f3a6cd587"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre class=language-r><code>function (...) \n",
              "{\n",
              "<span style=white-space:pre-wrap>    set2(resolve(...))</span>\n",
              "}</code></pre>"
            ],
            "text/markdown": "```r\nfunction (...) \n{\n    set2(resolve(...))\n}\n```",
            "text/latex": "\\begin{minted}{r}\nfunction (...) \n\\{\n    set2(resolve(...))\n\\}\n\\end{minted}",
            "text/plain": [
              "function (...) \n",
              "{\n",
              "    set2(resolve(...))\n",
              "}\n",
              "<bytecode: 0x578563a10558>\n",
              "<environment: 0x578563ab9be0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘crul’\n",
            "\n",
            "\n",
            "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
            "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
            "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.1     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32m%||%()\u001b[39m   masks \u001b[34mbase\u001b[39m::%||%()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
            "\n",
            "Attaching package: ‘janitor’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    chisq.test, fisher.test\n",
            "\n",
            "\n",
            "here() starts at /content\n",
            "\n"
          ]
        }
      ],
      "source": [
        "knitr::opts_chunk$set\n",
        "\n",
        "install.packages(\"lubridate\")\n",
        "install.packages(\"janitor\")\n",
        "install.packages(\"here\")\n",
        "install.packages(\"worrms\")\n",
        "\n",
        "library(tidyverse)\n",
        "library(worrms)\n",
        "library(lubridate)\n",
        "library(janitor)\n",
        "library(here)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This .Rmd file contains the script used to standardize the count and size data of M. magister data collected during the Sentinels of Change (SOC) project. Through this script, the data is standardized to Darwin Core to allow interoperability with other data records in the Ocean Biodiversity Information System (OBIS).\n",
        "\n",
        "Read in the files from the _data_ folder. Individual years are included as subfolders, the `Master_QAQC_LightTrap_Counts.csv` file contains the QAQCd count data from all sampling years, and the `megalopae_width_photo_calipers.csv` file contains the carapace width data. As per the [Sentinels of Change Light Trap Network DMP](https://dmptool.org/plans/78175), some problematic data entries should be filtered out during data analyses and are therefore omitted from the standardized data on OBIS. These problematic data entries are found under \"error_code\" and include `MET` (missing metadata), `BAT` (trap fished for over 25 hours), `DNF` (trap did not fish properly), and `ERR` (protocols not followed properly and counts likely not accurate)."
      ],
      "metadata": {
        "id": "ITDNc67c8a-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the station data:\n",
        "stations <- read_csv(here(\"data\", \"Master_Stations.csv\")) %>%\n",
        "  janitor::clean_names() %>%\n",
        "  select(code, site, organization)\n",
        "\n",
        "# Read in the count data:\n",
        "dung_count <- read_csv(here(\"data\", \"Master_QAQC_LightTrap_Counts.csv\")) %>%\n",
        "  janitor::clean_names() %>%\n",
        "  filter(!error_code %in% c(\"BAT\", \"MET\", \"MDNF\", \"ERR\")) %>%\n",
        "  select(code, site, lat, lon, year, month, date, weather, hours_fished, nights_fished,\n",
        "         metacarcinus_magister_megalopae, metacarcinus_magister_instar) %>%\n",
        "  mutate(project = \"SOC\",\n",
        "         trap = paste(project, code, sep = \"-\"))\n",
        "\n",
        "# Read in associated carapace width (cw) data.\n",
        "cw_2022 <- read_csv(here(\"data\", \"2022\", \"megalopae_widths_photo_calipers.csv\")) %>%\n",
        "  janitor::clean_names() %>%\n",
        "  rename(site = location) %>%\n",
        "  left_join(stations, by = \"site\")\n",
        "\n",
        "cw_2023 <- read_csv(here(\"data\", \"2023\", \"2023 Measurement Analysis.csv\")) %>%\n",
        "  janitor::clean_names() %>%\n",
        "  rename(site = location) %>%\n",
        "  left_join(stations, by = \"site\")\n",
        "\n",
        "# Combine all individual years of data. Add additional years' of data when available:\n",
        "carapace <- plyr::rbind.fill(cw_2022, cw_2023)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c2sLq8PZHvwx",
        "outputId": "73d445fd-a036-4e15-9ec8-d2f275472200"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m37\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m8\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m (4): Code, Site, Organization, Comment\n",
            "\u001b[32mdbl\u001b[39m (4): Lat, Lon, trap_checks2022, trap_checks2023\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "\u001b[1mRows: \u001b[22m\u001b[34m2432\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m17\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m   (6): Code, Site, Month, Weather, Subsample, Error_Code\n",
            "\u001b[32mdbl\u001b[39m  (10): Lat, Lon, Year, Nights_Fished, Hours_Fished, Metacarcinus_magiste...\n",
            "\u001b[34mdate\u001b[39m  (1): Date\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error: '/content/data/2022/megalopae_widths_photo_calipers.csv' does not exist.\n",
          "traceback": [
            "Error: '/content/data/2022/megalopae_widths_photo_calipers.csv' does not exist.\nTraceback:\n",
            "1. read_csv(here(\"data\", \"2022\", \"megalopae_widths_photo_calipers.csv\")) %>% \n .     janitor::clean_names() %>% rename(site = location) %>% left_join(stations, \n .     by = \"site\")",
            "2. left_join(., stations, by = \"site\")",
            "3. rename(., site = location)",
            "4. janitor::clean_names(.)",
            "5. read_csv(here(\"data\", \"2022\", \"megalopae_widths_photo_calipers.csv\"))",
            "6. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
            "7. vroom_(file, delim = delim %||% col_types$delim, col_names = col_names, \n .     col_types = col_types, id = id, skip = skip, col_select = col_select, \n .     name_repair = .name_repair, na = na, quote = quote, trim_ws = trim_ws, \n .     escape_double = escape_double, escape_backslash = escape_backslash, \n .     comment = comment, skip_empty_rows = skip_empty_rows, locale = locale, \n .     guess_max = guess_max, n_max = n_max, altrep = vroom_altrep(altrep), \n .     num_threads = num_threads, progress = progress)",
            "8. (function (path, write = FALSE) \n . {\n .     if (is.raw(path)) {\n .         return(rawConnection(path, \"rb\"))\n .     }\n .     if (!is.character(path)) {\n .         return(path)\n .     }\n .     if (is_url(path)) {\n .         if (requireNamespace(\"curl\", quietly = TRUE)) {\n .             con <- curl::curl(path)\n .         }\n .         else {\n .             inform(\"`curl` package not installed, falling back to using `url()`\")\n .             con <- url(path)\n .         }\n .         ext <- tolower(tools::file_ext(path))\n .         return(switch(ext, zip = , bz2 = , xz = {\n .             close(con)\n .             stop(\"Reading from remote `\", ext, \"` compressed files is not supported,\\n\", \n .                 \"  download the files locally first.\", call. = FALSE)\n .         }, gz = gzcon(con), con))\n .     }\n .     path <- enc2utf8(path)\n .     p <- split_path_ext(basename_utf8(path))\n .     if (write) {\n .         path <- normalizePath_utf8(path, mustWork = FALSE)\n .     }\n .     else {\n .         path <- check_path(path)\n .     }\n .     if (is_installed(\"archive\")) {\n .         formats <- archive_formats(p$extension)\n .         extension <- p$extension\n .         while (is.null(formats) && nzchar(extension)) {\n .             extension <- split_path_ext(extension)$extension\n .             formats <- archive_formats(extension)\n .         }\n .         if (!is.null(formats)) {\n .             p$extension <- extension\n .             if (write) {\n .                 if (is.null(formats[[1]])) {\n .                   return(archive::file_write(path, filter = formats[[2]]))\n .                 }\n .                 return(archive::archive_write(path, p$path, format = formats[[1]], \n .                   filter = formats[[2]]))\n .             }\n .             if (is.null(formats[[1]])) {\n .                 return(archive::file_read(path, filter = formats[[2]]))\n .             }\n .             return(archive::archive_read(path, format = formats[[1]], \n .                 filter = formats[[2]]))\n .         }\n .     }\n .     if (!write) {\n .         compression <- detect_compression(path)\n .     }\n .     else {\n .         compression <- NA\n .     }\n .     if (is.na(compression)) {\n .         compression <- tools::file_ext(path)\n .     }\n .     if (write && compression == \"zip\") {\n .         stop(\"Can only read from, not write to, .zip\", call. = FALSE)\n .     }\n .     switch(compression, gz = gzfile(path, \"\"), bz2 = bzfile(path, \n .         \"\"), xz = xzfile(path, \"\"), zip = zipfile(path, \"\"), \n .         if (!has_trailing_newline(path)) {\n .             file(path)\n .         } else {\n .             path\n .         })\n . })(\"/content/data/2022/megalopae_widths_photo_calipers.csv\")",
            "9. check_path(path)",
            "10. stop(\"'\", path, \"' does not exist\", if (!is_absolute_path(path)) {\n  .     paste0(\" in current working directory ('\", getwd(), \"')\")\n  . }, \".\", call. = FALSE)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1. Event Core\n",
        "\n",
        "Given that there's a sampling event (the deployment of the LED light trap at several stations) for this project, our schema will consist of an Event Core (Section 1) and three extension data tables: occurrence (Section 2), resourceRelationship (Section 3) and extended measurementOrFact (Section 4). In the final section (Section 5) we'll do some basic QAQC to ensure the formatted data follows the standards outlined in the DwC schema. The event table will include information on the sampling event, such as date, location, organization responsible for collecting and owning the data, and data related to the sampling effort (hours fished)."
      ],
      "metadata": {
        "id": "NjCXJuWJ8tfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add information that's general to the overall project\n",
        "project <- dung_count %>%\n",
        "  select(eventID = project) %>%\n",
        "  mutate(type = \"project\",\n",
        "         language = \"en\",\n",
        "         license = \"http://creativecommons.org/licenses/by/4.0/legalcode\",\n",
        "         bibliographicCitation = \"Whalen, M., & Earle, H. (2023). Larval Dungeness crab arrival, abundance, and size in the Salish Sea, British Columbia [Data set]. Hakai Institute. https://doi.org/10.21966/36hp-7f40\",\n",
        "         accessRights = \"https://github.com/timvdstap/sentinels-light-trap/blob/main/LICENSE\", #TODO: Change this to sentinels repo.\n",
        "         samplingProtocol = \"LED light trap\", #TODO: if public protocol exists (with DOI?) link to that.\n",
        "         rightsHolder = \"Hakai Institute\",\n",
        "         institutionCode = \"Hakai Institute\",\n",
        "         institutionID = \"https://edmo.seadatanet.org/report/5148\",\n",
        "         modified = lubridate::today(),\n",
        "         country = \"Canada\",\n",
        "         countryCode = \"CA\") %>%\n",
        "  distinct()\n",
        "\n",
        "# Add information specific to the traps\n",
        "trap <- dung_count %>%\n",
        "  select(eventID = trap,\n",
        "         parentEventID = project,\n",
        "         verbatimLocality = site) %>%\n",
        "  mutate(type = \"station\",\n",
        "         minimumDepthInMeters = 0,\n",
        "         maximumDepthInMeters = 2,) %>%\n",
        "  distinct(eventID, .keep_all = TRUE)\n",
        "\n",
        "# add metadata on specific sampling events ('station visits'):\n",
        "stationVisit <- dung_count %>%\n",
        "  select(parentEventID = trap,\n",
        "         sampleSizeValue = hours_fished,\n",
        "         decimalLatitude = lat,\n",
        "         decimalLongitude = lon,\n",
        "         eventDate = date,\n",
        "         weather,\n",
        "         nights_fished) %>%\n",
        "  mutate(type = \"stationVisit\",\n",
        "         year = as.numeric(format(as.Date(dung_count$date), \"%Y\")),\n",
        "         month = as.numeric(format(as.Date(dung_count$date), \"%m\")),\n",
        "         day = as.numeric(format(as.Date(dung_count$date), \"%d\")),\n",
        "         eventID = paste(parentEventID, year, month, day, sep = \"-\"),\n",
        "         sampleSizeEffort = paste(sampleSizeValue, \"hours of light trap fishing\"),\n",
        "         sampleSizeUnit = \"hours\",\n",
        "         geodeticDatum = \"WGS84\",\n",
        "         footprintWKT = paste(\"POINT\", \" (\", decimalLongitude, \" \", decimalLatitude, \")\"),\n",
        "         eventRemarks = ifelse(!is.na(weather), paste0(weather, \".\"), \"\")) %>%\n",
        "  mutate(eventRemarks = ifelse(nights_fished == 1, paste(eventRemarks, \"Hours fished were spread over\", nights_fished, \"night.\"),\n",
        "                               ifelse(nights_fished == 2, paste(eventRemarks, \"Hours fished were spread over\", nights_fished, \"nights.\"),\n",
        "                               eventRemarks))) %>%\n",
        "  select(-c(weather, nights_fished)) %>%\n",
        "  distinct(eventID, .keep_all = TRUE)\n",
        "\n",
        "# Merge these data tables:\n",
        "SOC_event <- bind_rows(project, trap, stationVisit) %>%\n",
        "  mutate_all(as.character)\n",
        "\n",
        "# Flatten event records\n",
        "SOC_event <- obistools::flatten_event(SOC_event)\n",
        "\n",
        "#TODO: Figure out whether there is a specific coordinateUncertainty from GPS. coordinateUncertaintyInMeters might be important because sites are so close to shore.\n",
        "\n",
        "# Remove NAs from the dataframe and save locally:\n",
        "SOC_event[is.na(SOC_event)] <- \"\"\n",
        "SOC_event <- as_tibble(SOC_event)\n",
        "write_csv(SOC_event, here(\"obis\", \"SOC_event.csv\"))"
      ],
      "metadata": {
        "id": "T9JNl7l286Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2. Occurrence extension\n",
        "\n",
        "The first extension that we create is the occurrence extension. We create two tables which we'll eventually join. The first occurrence extension table will contain the OccurrenceIDs that are nested under an eventID. These occurrenceIDs will uniquely reflect the count of M. magister instar and megalopae lifestages during each sampling event. When creating the occurrenceID I will `group_by` eventID, in the event that future iterations of this dataset will include bycatch. This should ensure that occurrenceID will remain the same irrespective of these species being added.\n",
        "\n",
        "The second extension data table is used to create unique occurrenceIDs for individual measurements. As the individual measurements are done just on the _megalopae_, **not** on the instar lifestage, we'll have to filter for those and then eventually ensure that for users of this data, it is clear that these occurrences are `nested` under the occurrenceID (that includes individualCount). In other words, we have to ensure that users understand that the individual measurements were not done from a separate sampling event than the overall count data associated with the event. We elaborate on this relationship in the `resourceRelationship` extension (Section 3)."
      ],
      "metadata": {
        "id": "Cab4pziF9BT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "occ <- left_join(dung_count, stations, by = c(\"code\", \"site\")) %>%\n",
        "  mutate(year = as.numeric(format(as.Date(dung_count$date), \"%Y\")),\n",
        "         month = as.numeric(format(as.Date(dung_count$date), \"%m\")),\n",
        "         day = as.numeric(format(as.Date(dung_count$date), \"%d\")),\n",
        "         eventID = paste(\"SOC\", code, year, month,day, sep = \"-\")) %>%\n",
        "  select(eventID, organization, metacarcinus_magister_instar, metacarcinus_magister_megalopae) %>%\n",
        "  pivot_longer(metacarcinus_magister_instar:metacarcinus_magister_megalopae,\n",
        "               names_to = \"verbatimIdentification\",\n",
        "               values_to = \"individualCount\")\n",
        "\n",
        "# Add lifestage columns:\n",
        "occ <- occ %>%\n",
        "  mutate(lifeStage = case_when(\n",
        "    grepl(\"megalopae\", verbatimIdentification) ~ \"megalopae\",\n",
        "    grepl(\"instar\", verbatimIdentification) ~ \"instar\"))\n",
        "\n",
        "# Add column with scientific name so we can match that to WoRMS. Easy as it's only 1 species!\n",
        "occ <- occ %>% mutate(scientificName = \"Metacarcinus magister\")\n",
        "\n",
        "soc_worms <- worrms::wm_records_names(unique(occ$scientificName), marine_only = T) %>%\n",
        "  dplyr::bind_rows() %>% rename(scientificName = scientificname)\n",
        "\n",
        "# Join back to the occurrence table:\n",
        "occ <- left_join(occ, soc_worms, by = \"scientificName\")\n",
        "\n",
        "# Add additional fields, such as specificEpithet, occurrenceID, occurrenceStatus and basisOfRecord\n",
        "occ <- occ %>%\n",
        "  mutate(specificEpithet = stringr::word(scientificName, 2),\n",
        "         authority = str_replace_all(authority, \"\\\\(|\\\\)\", \"\"),\n",
        "         scientificName = ifelse(!is.na(authority),\n",
        "                                 paste0(scientificName, \" (\", authority, \")\"),\n",
        "                                 scientificName)) %>%\n",
        "  group_by(eventID) %>%\n",
        "  mutate(occurrenceID = paste(eventID, row_number(), sep = \"-\"),\n",
        "         occurrenceStatus = ifelse(individualCount > 0, \"present\", \"absent\"),\n",
        "         basisOfRecord = \"HumanObservation\",\n",
        "         identificationVerificationStatus = \"ValidatedByHuman\") %>% #TODO: Confirm with Heather that all entries are manually checked/verified.\n",
        "  ungroup()\n",
        "\n",
        "# Select columns for the occurrence extension:\n",
        "SOC_occ <- occ %>%\n",
        "  select(eventID, verbatimIdentification,\n",
        "         recordedBy = organization,\n",
        "         individualCount, scientificName,\n",
        "         scientificNameID = lsid,\n",
        "         taxonRank = rank,\n",
        "         scientificNameAuthorship = authority,\n",
        "         taxonomicStatus = status,\n",
        "         occurrenceID,\n",
        "         occurrenceStatus,\n",
        "         kingdom, phylum, class, order, family, genus, specificEpithet,\n",
        "         lifeStage, basisOfRecord, identificationVerificationStatus)"
      ],
      "metadata": {
        "id": "BmdIxUzL9EOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create the 'second occurrence extension' data table, to include occurrenceIDs for just the megalopae lifestage occurrences. Instar lifestages were not measured. We'll use these individual occurrenceIDs in the extended measurement or fact extension as well."
      ],
      "metadata": {
        "id": "0Jmh0lwU9HNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp <- SOC_occ %>%\n",
        "  filter(lifeStage == \"megalopae\") %>%\n",
        "  select(eventID, occurrenceID, individualCount)\n",
        "\n",
        "# From the carapace data table, extract day, month and year from the date to help create the eventID:\n",
        "carapace$day <- as.numeric(format(as.Date(carapace$date, format = \"%m/%d/%Y\"), \"%d\"))\n",
        "carapace$month <- as.numeric(format(as.Date(carapace$date, format = \"%m/%d/%Y\"), \"%m\"))\n",
        "carapace$year <- as.numeric(format(as.Date(carapace$date, format = \"%m/%d/%Y\"), \"%Y\"))\n",
        "carapace$eventID <- paste(\"SOC\", carapace$code, carapace$year, carapace$month, carapace$day, sep = \"-\")\n",
        "\n",
        "carapace <- left_join(temp, carapace, by = \"eventID\") %>%\n",
        "  mutate_all(as.character) %>%\n",
        "  select(-c(week_start_date, photo_quality, comments, total_measured, mean, sd, se)) %>%\n",
        "  pivot_longer(m1:m30,\n",
        "               names_to = \"measurementType\",\n",
        "               values_to = \"measurementValue\")\n",
        "\n",
        "# Remove rows where measurementValue is NA\n",
        "carapace <- carapace %>% drop_na(measurementValue)\n",
        "\n",
        "# We want to assign an occurrenceID. For this, we'll want to:\n",
        "# 1) parse out the measurementType (i.e. length1) into a character string (length) and numerical value (1)\n",
        "# 2) Include 'ind' in the occurrenceID as this will make it easier to query in the resourceRelationship extension.\n",
        "\n",
        "cw_ind <- carapace %>%\n",
        "  separate(., measurementType, into = c(\"text\", \"num\"),\n",
        "           sep = \"(?<=[A-Za-z])(?=[0-9])\") %>%\n",
        "  mutate(occurrenceID = paste(occurrenceID, \"ind\", num, sep = \"-\")) %>%\n",
        "  select(eventID, occurrenceID,\n",
        "         measurementType = text,\n",
        "         measurementValue,\n",
        "         technique) %>%\n",
        "  mutate(across(\"measurementType\", str_replace, \"m\", \"carapace width\"),\n",
        "         individualCount = NA) %>%\n",
        "  distinct()"
      ],
      "metadata": {
        "id": "qq0g9Mxo9Iyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we combine these two occurrence data tables. I prefer re-ordering the occurrenceIDs to better visualize the nested hierarchy. After doing this, we fill in all the columns to match the information from the row above. We do this for all columns _except_ individualCount. We don't populate the individualCount for occurrenceIDs related to a single individual because this might confuse users in thinking that this value is in addition to the individualCount associated with the overall count."
      ],
      "metadata": {
        "id": "njq88fCN9N1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_occ <- dplyr::bind_rows(SOC_occ, cw_ind)\n",
        "\n",
        "# Re-order the occurrenceIDs, remove columns for measurementType and measurementValue:\n",
        "order <- stringr::str_sort(overall_occ$occurrenceID, numeric = TRUE)\n",
        "SOC_occ_extension <- overall_occ[match(order, overall_occ$occurrenceID),]\n",
        "SOC_occ_extension <- SOC_occ_extension %>% fill(c(verbatimIdentification, recordedBy, scientificName, scientificNameID, taxonRank, scientificNameAuthorship,\n",
        "                                  taxonomicStatus, occurrenceStatus, kingdom, phylum, class, order, family, genus, specificEpithet,\n",
        "                                  lifeStage, basisOfRecord, identificationVerificationStatus)) %>%\n",
        "  select(-c(measurementType, measurementValue, technique))\n",
        "\n",
        "# Remove NAs and save locally in the obis folder:\n",
        "SOC_occ_extension <- SOC_occ_extension %>% mutate_all(as.character)\n",
        "SOC_occ_extension[is.na(SOC_occ_extension)] <- \"\"\n",
        "SOC_occ_extension <- as_tibble(SOC_occ_extension)\n",
        "write_csv(SOC_occ_extension, here(\"obis\", \"SOC_occ.csv\"))"
      ],
      "metadata": {
        "id": "-FutkN6Y9Pvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3. Resource Relationship extension\n",
        "\n",
        "In the next section/extension table, we want to explicitly state the relation that individual measurements have to the 'umbrella' occurrenceID. This will help users understand that sometimes only a subset of the total individualCount were measured individually, and furthermore that when tallying the total count of megalopae at a sampling event, they should not be adding these values (hence why left individualCount empty) to the overall individualCount. We specify this relationship in the `resourceRelationship` extension."
      ],
      "metadata": {
        "id": "2k-wHl6Y9SLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOC_resourceRelationship <- SOC_occ_extension %>%\n",
        "  select(eventID, occurrenceID, scientificName) %>%\n",
        "  mutate(resourceID = ifelse(grepl(\"ind\", SOC_occ_extension$occurrenceID), SOC_occ_extension$occurrenceID, NA),\n",
        "         relatedResourceID = ifelse(grepl(\"ind\", SOC_occ_extension$occurrenceID), NA, SOC_occ_extension$occurrenceID),\n",
        "         relationshipOfResource = ifelse(!is.na(resourceID), \"is a subset of\", NA)) %>%\n",
        "  dplyr::arrange(eventID, scientificName) %>%\n",
        "  fill(relatedResourceID) %>%\n",
        "  filter(!is.na(resourceID))\n",
        "\n",
        "order <- stringr::str_sort(SOC_resourceRelationship$resourceID, numeric = TRUE)\n",
        "SOC_resourceRelationship <- SOC_resourceRelationship[match(order, SOC_resourceRelationship$resourceID),]\n",
        "\n",
        "SOC_resourceRelationship <- SOC_resourceRelationship %>%\n",
        "  mutate(resourceRelationshipID = paste(relatedResourceID, \"rr\", sep = \"-\"),\n",
        "         ID = sprintf(\"%03d\", row_number()),\n",
        "         resourceRelationshipID = paste(resourceRelationshipID, ID, sep = \"-\")) %>%\n",
        "  select(eventID, resourceRelationshipID, resourceID, relationshipOfResource, relatedResourceID)\n",
        "\n",
        "write_csv(SOC_resourceRelationship, here(\"obis\", \"SOC_resourceRelationship.csv\"))"
      ],
      "metadata": {
        "id": "EvRCWqun9UrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4. Extended measurement Or Fact extension\n",
        "\n",
        "Finally, we create the extended measurementOrFact (eMOF) data table, which will include information on sampling effort, as well as carapace width measurements and controlled vocabulary for the M. magister observed (count, lifestage, carapace width). Initially, we create separate tables because measurements or facts are associated at different levels (project, stationVisit and individual measurements). The measurementIDs created will be nested either directly under the eventID (when it concerns the measurements or facts on the sampling event), or more directly nested under the occurrenceID when it concerns biometric data."
      ],
      "metadata": {
        "id": "q0CXiGxp9Wdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measurements or facts data related to the sampling efforts:\n",
        "emof_project <- project %>%\n",
        "  select(eventID,\n",
        "         measurementValue = samplingProtocol) %>%\n",
        "  mutate(measurementType = \"sampling_method\",\n",
        "         measurementID = paste(eventID, measurementType, row_number(), sep = \"-\"),\n",
        "         measurementValueID = \"BODC Term requested\",\n",
        "         measurementTypeID = \"https://vocab.nerc.ac.uk/collection/Q01/current/Q0100003/\",\n",
        "         measurementUnit = \"not applicable\",\n",
        "         measurementUnitID = \"https://vocab.nerc.ac.uk/collection/P06/current/XXXX/\")\n",
        "\n",
        "emof_trap_effort <- stationVisit %>%\n",
        "  select(eventID,\n",
        "         measurementValue = sampleSizeValue) %>%\n",
        "  mutate(measurementType = \"hours_fished\",\n",
        "         measurementID = paste(eventID, measurementType, row_number(), sep = \"-\"),\n",
        "         measurementValueID = \"\",\n",
        "         measurementTypeID = \"http://vocab.nerc.ac.uk/collection/P01/current/AZDRZZ01\",\n",
        "         measurementUnit = \"hours\",\n",
        "         measurementUnitID = \"http://vocab.nerc.ac.uk/collection/P06/current/UHOR/\")\n",
        "\n",
        "# Measurements related to the overall occurrenceID (count, lifestage)\n",
        "emof_occ <- left_join(SOC_event, SOC_occ, by = \"eventID\") %>%\n",
        "  select(eventID, occurrenceID, individualCount, lifeStage) %>%\n",
        "  distinct(occurrenceID, .keep_all = T) %>%\n",
        "  mutate_all(as.character) %>%\n",
        "  pivot_longer(cols = individualCount:lifeStage,\n",
        "               names_to = \"measurementType\",\n",
        "               values_to = \"measurementValue\") %>%\n",
        "  mutate(measurementID = paste(occurrenceID, row_number(), sep = \"-\")) %>%\n",
        "  mutate(measurementTypeID = case_when(\n",
        "    measurementType == \"lifeStage\" ~ \"http://vocab.nerc.ac.uk/collection/P01/current/LSTAGE01/\",\n",
        "    measurementType == \"individualCount\" ~ \"http://vocab.nerc.ac.uk/collection/P01/current/OCOUNT01/\")) %>%\n",
        "  mutate(measurementValueID = case_when(\n",
        "    measurementValue == \"instar\" ~ \"http://vocab.nerc.ac.uk/collection/S11/current/S1105/\",\n",
        "    measurementValue == \"megalopae\" ~ \"http://vocab.nerc.ac.uk/collection/S11/current/S1167/\")) %>%\n",
        "  mutate(measurementUnit = case_when(\n",
        "    measurementType == \"individualCount\" ~ \"individuals\",\n",
        "    measurementType == \"lifeStage\" ~ \"not applicable\")) %>%\n",
        "  mutate(measurementUnitID = case_when(\n",
        "    measurementUnit == \"individuals\" ~ \"http://vocab.nerc.ac.uk/collection/P06/current/UUUU/\",\n",
        "    measurementUnit == \"not applicable\" ~ \"https://vocab.nerc.ac.uk/collection/P06/current/XXXX/\"))\n",
        "\n",
        "# Measurements (carapace width) related to individuals:\n",
        "emof_carapace <- cw_ind %>%\n",
        "  mutate(measurementID = paste(occurrenceID, row_number(), sep = \"-\"),\n",
        "         measurementTypeID = case_when(\n",
        "           measurementType == \"carapace width\" ~ \"http://vocab.nerc.ac.uk/collection/P01/current/CAPWID01/\")) %>%\n",
        "  mutate(measurementUnit = \"mm\",\n",
        "         measurementUnitID = \"http://vocab.nerc.ac.uk/collection/P06/current/UXMM/\") %>%\n",
        "  rename(measurementMethod = technique) %>%\n",
        "  select(-individualCount)\n",
        "\n",
        "# Combine the two emof data tables:\n",
        "SOC_emof <- plyr::rbind.fill(emof_project, emof_trap_effort, emof_occ, emof_carapace)\n",
        "\n",
        "# Remove NAs:\n",
        "SOC_emof[is.na(SOC_emof)] <- \"\"\n",
        "SOC_emof <- as_tibble(SOC_emof)\n",
        "\n",
        "# Save locally as .csv file:\n",
        "write_csv(SOC_emof, here(\"obis\", \"SOC_emof.csv\"))"
      ],
      "metadata": {
        "id": "vICsj83g9Y_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5. Basic QAQC"
      ],
      "metadata": {
        "id": "INkMK7ri9crL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot points on a map:\n",
        "SOC_event$decimalLatitude <- as.numeric(SOC_event$decimalLatitude)\n",
        "SOC_event$decimalLongitude <- as.numeric(SOC_event$decimalLongitude)\n",
        "SOC_leaflet <- obistools::plot_map_leaflet(SOC_event)\n",
        "SOC_map <- obistools::plot_map(SOC_event, zoom = TRUE)\n",
        "ggsave(filename = \"SOC_map.png\", plot = SOC_map, path = here::here(\"obis\", \"maps\"))\n",
        "\n",
        "# -- check eventDate\n",
        "obistools::check_eventdate(SOC_event) # Confirm that this shows a 0 x 0 tibble (i.e. no errors).\n",
        "\n",
        "# As we're working with an Event Core, the fields for eventDate, decimalLatitude and decimalLongitude should be in that table (no need for duplication)\n",
        "obistools::check_fields(SOC_occ)\n",
        "\n",
        "# check_extension_eventids() checks if all eventIDs in an extension have a matching eventID in the core table (should be empty dataframe):\n",
        "obistools::check_extension_eventids(SOC_event, SOC_occ)"
      ],
      "metadata": {
        "id": "azXlzql89eTr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}